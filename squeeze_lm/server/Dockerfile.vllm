FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04 AS builder

# Set environment variables to prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive
# ENV TZ=Etc/UTC

# Install basic system utilities and Python essentials
RUN sed -i 's|http://archive.ubuntu.com/ubuntu/|https://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g' /etc/apt/sources.list && \
    sed -i 's|http://security.ubuntu.com/ubuntu/|https://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g' /etc/apt/sources.list && \
    apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    python3-venv \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Create a virtual environment for clean dependency management
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
# Upgrade pip and install the key libraries

RUN pip install --no-cache-dir --upgrade pip
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install flashinfer-python

# Install all dependencies including the FlashAttention kernels which need to be built from source.
# This can take some time.

# --- Stage 2: Final Production Image ---
FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
# ENV TZ=Etc/UTC
# Set a home for Hugging Face models so they don't go to the root user's home
ENV HF_ENDPOINT=https://hf-mirror.com
# Create the directory for model data and give our user ownership
RUN mkdir -p /data/huggingface
ENV HF_HOME=/data/huggingface
ENV PATH="/opt/venv/bin:$PATH"

# Install essential runtime utilities (htop for monitoring, nc for network checks)
RUN sed -i 's|http://archive.ubuntu.com/ubuntu/|https://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g' /etc/apt/sources.list && \
sed -i 's|http://security.ubuntu.com/ubuntu/|https://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g' /etc/apt/sources.list && \
apt-get update && apt-get install -y htop netcat \
python3.10-dev \
python3-venv \
&& rm -rf /var/lib/apt/lists/*

# Copy the virtual environment from the builder stage
COPY --from=builder /opt/venv /opt/venv

# Create a non-root user for better security
RUN useradd --create-home --shell /bin/bash appuser && chmod -R 777 /data
WORKDIR /home/appuser
USER appuser

ENV VLLM_ATTENTION_BACKEND=FLASHINFER

# The default command to start the vLLM server.
# This will be overridden by the 'command' in your Ansible playbook or docker run command.
EXPOSE 12434
CMD ["vllm","serve", "--host", "0.0.0.0", "--port", "12434", "--model", "meta-llama/Llama-2-7b-chat-hf"]